{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "This notebook covers the 80% of reading and writing files in pandas.</br>\n",
    "While there are a large number of options in the pandas API, this will focus on:\n",
    "* reading a directory\n",
    "* CSV\n",
    "* Parquet\n",
    "* JSON\n",
    "* Excel\n",
    "\n",
    "\n",
    "To use you need to have python installed and jupyterlab.  </br>\n",
    "The code assumes you have a basic familiarity with python syntax and use.\n",
    "## Packages Needed\n",
    "* sys\n",
    "* os\n",
    "* pandas\n",
    "* numpy\n",
    "* json\n",
    "* pyarrow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install & Import\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "\n",
    "'''\n",
    "Using \"!{sys.executable} -m pip install\"   instead of \"!pip install\"\n",
    "ensures that the install is done in the context and kernel currently running\n",
    "the notebook. This is a recommended best practice and I try to use this method within\n",
    "notebooks as I try to default to what I would want to see if I was collaborating with\n",
    "a group.\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Files used\n",
    "\n",
    "All files were downloaded and extracted in to a folder called \"data\" in the\n",
    "same folder as this notbook \"./data/*\"\n",
    "\n",
    "From Kaggle\n",
    "* https://www.kaggle.com/datasets/jeffreybraun/chipotle-locations\n",
    "    * chipotle_store.csv\n",
    "    * us-states.json\n",
    "\n",
    "\n",
    "From Github\n",
    "* https://github.com/Teradata/kylo/tree/master/samples/sample-data/parquet\n",
    "    * userdata1.parquet\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Looping files in a directory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print names of files in a directory and return them as a list.\n",
    "def return_files_as_list(directory):\n",
    "    files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file before printing and adding to the\n",
    "        # file list\n",
    "        if os.path.isfile(f):\n",
    "            print(f)\n",
    "            files.append(f)\n",
    "    return files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "return_files_as_list(\"./data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read/Write CSV\n",
    "docs:\n",
    " * https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    " * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chipotle_loc_df = pd.read_csv(\"./data/chipotle_stores.csv\")\n",
    "chipotle_loc_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chipotle_loc_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chipotle_loc_df.to_csv(\"./data/chipotle.tsv\", sep=\"\\t\", index=False)\n",
    "return_files_as_list(\"./data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsv_df = pd.read_csv(\"./data/chipotle.tsv\", sep=\"\\t\")\n",
    "tsv_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chunky chunks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "A method that is often taught too late or not at all is chunks.\n",
    "for large data sets or memory constrained compute like laptops, it is\n",
    "very helpful to learn chunk early.\n",
    "'''\n",
    "\n",
    "for chunk_df in pd.read_csv(\"./data/chipotle_stores.csv\", chunksize=2):\n",
    "    print(chunk_df.info())\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read/Write Parquet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parquet_df = pd.read_parquet(\"./data/userdata1.parquet\")\n",
    "parquet_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parquet_df[[\"first_name\", \"email\"]].to_parquet(\"./data/emails.parquet\")\n",
    "'''\n",
    "This uses Pyarrow under the hood to serialize the data\n",
    " and save the file\n",
    "'''\n",
    "emails_df = pd.read_parquet(\"./data/emails.parquet\")\n",
    "emails_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read/Write JSON"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_df = pd.read_json(\"./data/us-states.json\")\n",
    "json_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_data = json.load(open(\"./data/us-states.json\"))\n",
    "print(json.dumps(json_data, indent=2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_df2 = pd.DataFrame.from_records(json_data[\"features\"])\n",
    "json_df2.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_df3 = pd.DataFrame.from_dict(json_data[\"features\"]) # same as from records above\n",
    "json_df3 = pd.DataFrame.from_dict(json_data[\"features\"][0]) # gets wonky\n",
    "\n",
    "json_df3.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read/Write Excel\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parquet_df = pd.read_parquet(\"./data/userdata1.parquet\")\n",
    "parquet_df2 = pd.read_parquet(\"./data/userdata2.parquet\")\n",
    "parquet_df3 = pd.read_parquet(\"./data/userdata3.parquet\")\n",
    "parquet_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parquet_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parquet_df.to_excel(\"./data/output.xlsx\",\n",
    "             sheet_name='user_data_1')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('./data/output.xlsx') as writer:\n",
    "    parquet_df.to_excel(writer, sheet_name='user_data_1')\n",
    "    parquet_df2.to_excel(writer, sheet_name='user_data_2')\n",
    "    parquet_df2.to_excel(writer, sheet_name='user_data_3')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "excel_df = pd.read_excel(\"./data/output.xlsx\", sheet_name=\"user_data_1\")\n",
    "excel_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "excel_df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View all columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "excel_df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
